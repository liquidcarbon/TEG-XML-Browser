# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/03_TEG_XML_Parser.ipynb.

# %% auto 0
__all__ = ['config', 'sharepoint_url', 'credentials', 'ctx', 'TEGXMLProcessor', 'unstringify', 'xml_unstringify',
           'get_sharepoint_ids']

# %% ../notebooks/03_TEG_XML_Parser.ipynb 6
from collections import abc
from dotenv import dotenv_values
from loguru import logger as log
from office365.runtime.auth.user_credential import UserCredential
from office365.runtime.client_request_exception import ClientRequestException
from office365.sharepoint.client_context import ClientContext as SharePointClientContext
import ast
import io
import json
import os
import re
import sys
import xmltodict 

# %% ../notebooks/03_TEG_XML_Parser.ipynb 8
#| code-fold: true
class TEGXMLProcessor:
    """Pipeline for TEG6s XML processing."""

    ROOT_TAG = bytes("Cartridge", encoding="utf-8")  # assumption that this will be true

    @classmethod
    def from_local_file(
        cls,
        local_filepath: str  # path to input XML file
    ):
        """Read from a local XML file."""
        instance = cls()
        instance.local_filepath = local_filepath
        log.debug("reading from a local file...")

        try:
            with open(local_filepath, "rb") as f:
                instance.content = f.read()
            instance.raw_length = len(instance.content)
            log.info(f"Read {instance.raw_length:,d} bytes of raw XML data")
        except Exception as e:
            log.error(f"unable to read file: {e}")
        return instance

    @classmethod
    def from_sharepoint_guid(
        cls,
        ctx: SharePointClientContext,  # SharePoint connection object
        sharepoint_guid: str  # SharePoint globally unique ID
    ):
        """Read from SharePoint. Requires initialized ClientContext."""
        instance = cls()
        instance.sharepoint_guid = sharepoint_guid
        log.debug("reading from SharePoint...")

        try:
            with io.BytesIO() as bytestream:
                ctx.web.get_file_by_id(sharepoint_guid).download(bytestream).execute_query()
                instance.raw_length = bytestream.tell()
                log.info(f"read {instance.raw_length:,d} bytes from file {sharepoint_guid}")
                bytestream.seek(0)  # rewind IO buffer
                instance.content = bytestream.read()
        except Exception as e:
            log.error(f"unable to read SharePoint file: {e}")          
        return instance

    def find_xml_offsets(self):
        """Scans for XML fragments."""
        xml_open_bytes = [x.start() for x in re.finditer(b"<\?xml", self.content)]
        xml_close_bytes = [x.end() for x in re.finditer(self.ROOT_TAG+b">", self.content)]
        if len(xml_open_bytes) != len(xml_close_bytes):
            log.error("XML heads not equal XML tails")
        else:
            xml_offsets = [(start, end) for start, end in zip(xml_open_bytes, xml_close_bytes)]
            log.info(f"found {len(xml_offsets)} XML fragment(s)")
            return xml_offsets

    def parse(self):
        if self.content.startswith(b"<?xml"):
            _to_parse = self.content
        else:
            offsets = self.find_xml_offsets()
            start, end  = offsets[-1]  # this is an ASSUMPTION
            _to_parse = self.content[start:end]
        try:
            self.d = xmltodict.parse(
                _to_parse,
                attr_prefix="",
                postprocessor=xml_unstringify,
            )
            self.id = self.d["Cartridge"]["CartridgeResult"]["TestResultID"]
            log.info("XML parsed")
        except Exception as e:
            log.error(f"Nope: {e}")

    def pop_lists(self):
        """Recursively iterate through dictionary and pop all lists into a separate object."""
        self.lists = {}
        def walk_and_pop(nested_dict, path=tuple()):
            for key, value in nested_dict.copy().items():
                nested_path = path + (key,)
                if isinstance(value, list):  # is it a list? pop it
                    self.lists[nested_path] = nested_dict.pop(key)
                elif isinstance(value, abc.Mapping):  # https://stackoverflow.com/a/35691011/9511034
                    walk_and_pop(value, path=nested_path)  # is it a dict? go deeper
                else:
                    continue
        walk_and_pop(self.d)
        return

    def save_jsons(self):
        """Saves parsed XML data in JSON files."""
        metadata_filepath = self.filepath.rstrip(".xml") + "_metadata.json"
        self.save_metadata_json(output_filepath=metadata_filepath)
        
    def save_metadata_json(
        self,
        output_filepath: str  # path to output file
    ):
        """Saves metadata as a JSON file."""
        _output = json.dumps(self.d, indent=4)
        with open(output_filepath, "w") as f:
            f.write(_output)
        log.info(f"wrote {len(_output):,d} bytes to {output_filepath}")


def unstringify(value):
    """Converts stringified numbers to integers or floats."""
    try:
        value = ast.literal_eval(val)
    except:
        pass
    return value


def xml_unstringify(path, key, value):
    """Used as a callable for `xmldict.parse`.
    
    Casts numbers that appears as strings in XML back to integers or floats.
    """
    if value == "true":
        value = "True"
    if value == "false":
        value = "False"
    return key, unstringify(value)

# %% ../notebooks/03_TEG_XML_Parser.ipynb 14
config = dotenv_values("../.env")
sharepoint_url = config["SHAREPOINT_URL"]
credentials = UserCredential(config["USERNAME"], config["PASSWORD"])
ctx = SharePointClientContext(sharepoint_url).with_credentials(credentials)

# %% ../notebooks/03_TEG_XML_Parser.ipynb 24
#| code-fold: true
def get_sharepoint_ids(
    parent_folder_url: str,  # SharePoint URL (TODO: %20 URL formatting)
    ctx: SharePointClientContext,  # SharePoint connection object
):
    """Recursively traverse files and folders and retrieve SharePoint GUIDs."""

    sharepoint_folder = ctx.web.get_folder_by_server_relative_url(parent_folder_url).get().execute_query()

    def traverse_sharepoint_folder(parent_folder, file_dict):
        parent_folder.expand(["Files", "Folders"]).get().execute_query()
        for file in parent_folder.files:
            if file.name.endswith(".xml"):
                file_prefix = file.name.split('/')[-1].split('-')[0]
                if file_prefix in ["Cartridge_PAT","Cartridge_WET"]:
                  file_dict[file.serverRelativeUrl] = file.unique_id
        for folder in parent_folder.folders:
            traverse_sharepoint_folder(folder, file_dict=file_dict)       

    file_dict = {}
    traverse_sharepoint_folder(sharepoint_folder, file_dict)
    return file_dict
